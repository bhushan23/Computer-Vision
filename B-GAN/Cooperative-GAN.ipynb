{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as tutils\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "imgDim = 28\n",
    "path = './genImg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(root='../Data/MNIST',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    IS_CUDA = True\n",
    "    \n",
    "def var(x):\n",
    "    if IS_CUDA:\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.data.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def save_image(pic, path):\n",
    "    grid = torchvision.utils.make_grid(pic.data, nrow=8, padding=2)\n",
    "    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    im.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator_input = 64\n",
    "'''\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.resize(batch_size, 1, imgDim, imgDim)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(x),2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "'''\n",
    "    \n",
    "    \n",
    "D = nn.Sequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256,1),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "Generator_input = 64\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(Generator_input, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Sequential(nn.Linear(256, 784), nn.Tanh())\n",
    "        self.lR = nn.LeakyReLU(0.2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.lR(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.lR(x)\n",
    "        return self.fc3(x)\n",
    "'''\n",
    "\n",
    "Generator = nn.Sequential(\n",
    "        nn.Linear(Generator_input, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 784),\n",
    "        nn.Tanh())\n",
    "\n",
    "'''\n",
    "#D = Discriminator()\n",
    "\n",
    "# Create n Generators\n",
    "#Gen = copy.deepcopy(Generator)\n",
    "Gen = Generator()\n",
    "Generators = []\n",
    "GOptimizers = []\n",
    "NumberOfGenerators = 3\n",
    "for i in range(NumberOfGenerators):\n",
    "    #Generators.append(copy.deepcopy(Generator))\n",
    "    Generators.append(Generator())\n",
    "\n",
    "if IS_CUDA:\n",
    "    D.cuda()\n",
    "    for each in Generators:\n",
    "        each.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCriterion = nn.BCELoss()\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr = 0.0001)\n",
    "G_opt = torch.optim.Adam(Gen.parameters(), lr = 0.0001)\n",
    "GOptimizers = []\n",
    "for each in Generators:\n",
    "    GOptimizers.append(torch.optim.Adam(each.parameters(), lr = 0.0001))\n",
    "\n",
    "fixed_x = var(torch.randn(batch_size, Generator_input))\n",
    "\n",
    "GeneratorLoss = []\n",
    "def backPropGenerator(index, GeneratorLoss):\n",
    "    Generators[index].zero_grad()\n",
    "    GeneratorLoss[index].backward()\n",
    "    GOptimizers[index].step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "outputImages = []\n",
    "BestPerformingGenerator = 0\n",
    "def train(Gen, BestPerformingGenerator, num_epochs = 10, d_iter = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in data_loader:\n",
    "            image, _  = data\n",
    "            image = var(image.view(image.size(0),  -1))\n",
    "            \n",
    "            #Gen = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "            \n",
    "            # Train Discriminator\n",
    "            #for k in range(0, d_iter):\n",
    "            # For Log D(x)\n",
    "            #print image.shape\n",
    "            D_real = D(image)\n",
    "            # For Log(1 - D(G(Z)))\n",
    "            Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "            #print Z_noise.shape\n",
    "            #print type(Gen)\n",
    "            G_fake = Gen(Z_noise)\n",
    "            #print G_fake.shape\n",
    "            D_fake = D(G_fake)\n",
    "\n",
    "            # Calculate Discriminator Loss\n",
    "            D_real_loss = lossCriterion(D_real, var(torch.ones(batch_size, 1)))\n",
    "            D_fake_loss = lossCriterion(D_fake, var(torch.zeros(batch_size, 1)))\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "            # Backprop Discriminator\n",
    "            D.zero_grad()\n",
    "            D_loss.backward()\n",
    "            D_opt.step()\n",
    "   \n",
    "            # Train Generators\n",
    "            Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "            G_fake = Gen(Z_noise)\n",
    "            D_fake = D(G_fake)\n",
    "            # Compute Generator Loss\n",
    "            G_loss = lossCriterion(D_fake, var(torch.ones(batch_size, 1)))\n",
    "            \n",
    "            # Find best performing Generator\n",
    "            GeneratorLoss = []\n",
    "            lossList = []\n",
    "            for each in Generators:\n",
    "                Z_noise1 = var(torch.randn(batch_size, Generator_input))\n",
    "                G_fake1 = each(Z_noise1)\n",
    "                #print G_fake1.shape\n",
    "                #print type(each)\n",
    "                D_fake1 = D(G_fake1)\n",
    "                # Compute Generator Loss\n",
    "                G_loss1 = lossCriterion(D_fake1, var(torch.ones(batch_size, 1)))\n",
    "                GeneratorLoss.append(G_loss1)\n",
    "                lossList.append(float(G_loss1.data[0]))\n",
    "            \n",
    "            #print lossList\n",
    "            #print type(lossList[0])\n",
    "            BestPerformingGenerator = lossList.index(min(lossList))\n",
    "            \n",
    "            # Change other Generator with best performing ones config:\n",
    "            Gen = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "            G_opt = copy.deepcopy(GOptimizers[BestPerformingGenerator])\n",
    "\n",
    "            # Backprop Genearator\n",
    "            D.zero_grad()\n",
    "            Gen.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_opt.step()\n",
    "            \n",
    "            backPropGenerator(BestPerformingGenerator, GeneratorLoss)\n",
    "            \n",
    "            for i in range(NumberOfGenerators):\n",
    "                if i != BestPerformingGenerator:\n",
    "                    Generators[i] = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "                    GOptimizers[i] = copy.deepcopy(GOptimizers[BestPerformingGenerator])\n",
    "                    backPropGenerator(i, GeneratorLoss)\n",
    "                                \n",
    "        #print epoch\n",
    "        print 'Epoch [{}/{}], Discriminator {:.4f}, Generator {:.4f}'.format(epoch+1, num_epochs, D_loss.data[0], G_loss.data[0])\n",
    "        pic = Gen(var(torch.randn(batch_size, Generator_input))) #(fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, imgDim, imgDim) \n",
    "        outputImages.append(pic)\n",
    "        torchvision.utils.save_image(pic.data, path+'image_{}.png'.format(epoch)) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#train(Gen, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputImages = []\n",
    "def train(BestPerformingGenerator, num_epochs = 10, d_iter = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        lossList = [0.0] * NumberOfGenerators\n",
    "        for data in data_loader:\n",
    "            image, _  = data\n",
    "            image = var(image.view(image.size(0),  -1))\n",
    "            \n",
    "            #Gen = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "            \n",
    "            # Train Discriminator\n",
    "            #for k in range(0, d_iter):\n",
    "            # For Log D(x)\n",
    "            #print image.shape\n",
    "            #print 'Epoch [{}/{}].'.format(epoch+1, num_epochs)\n",
    "            \n",
    "            #for each in Generators:\n",
    "            D_real = D(image)\n",
    "            # For Log(1 - D(G(Z)))\n",
    "            Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "            #print Z_noise.shape\n",
    "            #print type(Gen)\n",
    "            G_fake = Generators[BestPerformingGenerator](Z_noise)\n",
    "            #print G_fake.shape\n",
    "            D_fake = D(G_fake)\n",
    "\n",
    "            # Calculate Discriminator Loss\n",
    "            D_real_loss = lossCriterion(D_real, var(torch.ones(batch_size, 1)))\n",
    "            D_fake_loss = lossCriterion(D_fake, var(torch.zeros(batch_size, 1)))\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "            # Backprop Discriminator\n",
    "            D.zero_grad()\n",
    "            D_loss.backward()\n",
    "            D_opt.step()\n",
    "                #print 'Discriminator Loop for: {}: {}'.format(i, D_loss.data[0])\n",
    "   \n",
    "            # Find best performing Generator\n",
    "            i = 0\n",
    "            GeneratorLoss = []\n",
    "            for each, each_opt in zip(Generators, GOptimizers):\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                G_fake = each(Z_noise)\n",
    "                #print G_fake1.shape\n",
    "                #print type(each)\n",
    "                D_fake = D(G_fake)\n",
    "                # Compute Generator Loss\n",
    "                G_loss = lossCriterion(D_fake, var(torch.ones(batch_size, 1)))\n",
    "                GeneratorLoss.append(G_loss)\n",
    "                lossList[i] += (float(G_loss.data[0]))\n",
    "                i = i + 1\n",
    "                D.zero_grad()\n",
    "                each.zero_grad()\n",
    "                G_loss.backward()\n",
    "                each_opt.step()\n",
    "                \n",
    "                #backPropGenerator(i, GeneratorLoss)\n",
    "                #print 'Generator Loop for: {}: {}'.format(i, G_loss.data[0])\n",
    "            \n",
    "            #print lossList\n",
    "            #print type(lossList[0])\n",
    "        BestPerformingGenerator = lossList.index(max(lossList)) # earlier was min\n",
    "        print lossList\n",
    "        for i in range(0, NumberOfGenerators):\n",
    "            if i != BestPerformingGenerator:\n",
    "                prev = Generators[i]\n",
    "                Generators[i] = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "                GOptimizers[i] = torch.optim.Adam(Generators[i].parameters(), lr = 0.0001)\n",
    "                #copy.deepcopy(GOptimizers[BestPerformingGenerator])\n",
    "                if Generators[i] == prev:\n",
    "                    print 'SAME'\n",
    "\n",
    "        #print epoch\n",
    "        #print BestPerformingGenerator\n",
    "        print 'Epoch [{}/{}], Discriminator {:.4f}, Best Generator[{}] {:.4f}'.format(epoch+1, num_epochs, D_loss.data[0], BestPerformingGenerator, GeneratorLoss[BestPerformingGenerator].data[0])\n",
    "        pic = Generators[BestPerformingGenerator](var(torch.randn(batch_size, Generator_input))) #(fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, imgDim, imgDim) \n",
    "        outputImages.append(pic)\n",
    "        #torchvision.utils.save_image(pic.data, path+'image_{}.png'.format(epoch))   \n",
    "        save_image(pic, path+'image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train D for every G\n",
    "\n",
    "outputImages = []\n",
    "def train(BestPerformingGenerator, num_epochs = 10, d_iter = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        lossList = [0.0] * NumberOfGenerators\n",
    "        for data in data_loader:\n",
    "            image, _  = data\n",
    "            image = var(image.view(image.size(0),  -1))\n",
    "            \n",
    "            #Gen = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "            \n",
    "            # Train Discriminator\n",
    "            #for k in range(0, d_iter):\n",
    "            # For Log D(x)\n",
    "            #print image.shape\n",
    "            #print 'Epoch [{}/{}].'.format(epoch+1, num_epochs)\n",
    "            \n",
    "            for each in Generators:\n",
    "                D_real = D(image)\n",
    "                # For Log(1 - D(G(Z)))\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                #print Z_noise.shape\n",
    "                #print type(Gen)\n",
    "                G_fake = each(Z_noise) #Generators[BestPerformingGenerator](Z_noise)\n",
    "                #print G_fake.shape\n",
    "                D_fake = D(G_fake)\n",
    "\n",
    "                # Calculate Discriminator Loss\n",
    "                D_real_loss = lossCriterion(D_real, var(torch.ones(batch_size, 1)))\n",
    "                D_fake_loss = lossCriterion(D_fake, var(torch.zeros(batch_size, 1)))\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "                # Backprop Discriminator\n",
    "                D.zero_grad()\n",
    "                D_loss.backward()\n",
    "                D_opt.step()\n",
    "                #print 'Discriminator Loop for: {}: {}'.format(i, D_loss.data[0])\n",
    "   \n",
    "            # Find best performing Generator\n",
    "            i = 0\n",
    "            GeneratorLoss = []\n",
    "            for each, each_opt in zip(Generators, GOptimizers):\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                G_fake = each(Z_noise)\n",
    "                #print G_fake1.shape\n",
    "                #print type(each)\n",
    "                D_fake = D(G_fake)\n",
    "                # Compute Generator Loss\n",
    "                G_loss = lossCriterion(D_fake, var(torch.ones(batch_size, 1)))\n",
    "                GeneratorLoss.append(G_loss)\n",
    "                lossList[i] += (float(G_loss.data[0]))\n",
    "                i = i + 1\n",
    "                D.zero_grad()\n",
    "                each.zero_grad()\n",
    "                G_loss.backward()\n",
    "                each_opt.step()\n",
    "                \n",
    "                #backPropGenerator(i, GeneratorLoss)\n",
    "                #print 'Generator Loop for: {}: {}'.format(i, G_loss.data[0])\n",
    "            \n",
    "            #print lossList\n",
    "            #print type(lossList[0])\n",
    "        BestPerformingGenerator = lossList.index(max(lossList)) # earlier was min\n",
    "        print lossList\n",
    "        for i in range(0, NumberOfGenerators):\n",
    "            if i != BestPerformingGenerator:\n",
    "                prev = Generators[i]\n",
    "                Generators[i] = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "                GOptimizers[i] = torch.optim.Adam(Generators[i].parameters(), lr = 0.0001)\n",
    "                #copy.deepcopy(GOptimizers[BestPerformingGenerator])\n",
    "                if Generators[i] == prev:\n",
    "                    print 'SAME'\n",
    "\n",
    "        #print epoch\n",
    "        #print BestPerformingGenerator\n",
    "        print 'Epoch [{}/{}], Discriminator {:.4f}, Best Generator[{}] {:.4f}'.format(epoch+1, num_epochs, D_loss.data[0], BestPerformingGenerator, GeneratorLoss[BestPerformingGenerator].data[0])\n",
    "        pic = Generators[BestPerformingGenerator](var(torch.randn(batch_size, Generator_input))) #(fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, imgDim, imgDim) \n",
    "        outputImages.append(pic)\n",
    "        #torchvision.utils.save_image(pic.data, path+'image_{}.png'.format(epoch))   \n",
    "        save_image(pic, path+'image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model instead of deepcopy\n",
    "\n",
    "outputImages = []\n",
    "def train(BestPerformingGenerator, num_epochs = 10, d_iter = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        lossList = [0.0] * NumberOfGenerators\n",
    "        for data in data_loader:\n",
    "            image, _  = data\n",
    "            image = var(image.view(image.size(0),  -1))\n",
    "            \n",
    "            #Gen = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "            \n",
    "            # Train Discriminator\n",
    "            #for k in range(0, d_iter):\n",
    "            # For Log D(x)\n",
    "            #print image.shape\n",
    "            #print 'Epoch [{}/{}].'.format(epoch+1, num_epochs)\n",
    "            \n",
    "            for each in Generators:\n",
    "                D_real = D(image)\n",
    "                # For Log(1 - D(G(Z)))\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                #print Z_noise.shape\n",
    "                #print type(Gen)\n",
    "                G_fake = each(Z_noise) #Generators[BestPerformingGenerator](Z_noise)\n",
    "                #print G_fake.shape\n",
    "                D_fake = D(G_fake)\n",
    "\n",
    "                # Calculate Discriminator Loss\n",
    "                D_real_loss = lossCriterion(D_real, var(torch.ones(batch_size, 1)))\n",
    "                D_fake_loss = lossCriterion(D_fake, var(torch.zeros(batch_size, 1)))\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "                # Backprop Discriminator\n",
    "                D.zero_grad()\n",
    "                D_loss.backward()\n",
    "                D_opt.step()\n",
    "                #print 'Discriminator Loop for: {}: {}'.format(i, D_loss.data[0])\n",
    "   \n",
    "            # Find best performing Generator\n",
    "            i = 0\n",
    "            GeneratorLoss = []\n",
    "            for each, each_opt in zip(Generators, GOptimizers):\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                G_fake = each(Z_noise)\n",
    "                #print G_fake1.shape\n",
    "                #print type(each)\n",
    "                D_fake = D(G_fake)\n",
    "                # Compute Generator Loss\n",
    "                G_loss = lossCriterion(D_fake, var(torch.ones(batch_size, 1)))\n",
    "                GeneratorLoss.append(G_loss)\n",
    "                lossList[i] += (float(G_loss.data[0]))\n",
    "                i = i + 1\n",
    "                D.zero_grad()\n",
    "                each.zero_grad()\n",
    "                G_loss.backward()\n",
    "                each_opt.step()\n",
    "                \n",
    "                #backPropGenerator(i, GeneratorLoss)\n",
    "                #print 'Generator Loop for: {}: {}'.format(i, G_loss.data[0])\n",
    "            \n",
    "            #print lossList\n",
    "            #print type(lossList[0])\n",
    "        BestPerformingGenerator = lossList.index(max(lossList)) # earlier was min\n",
    "        print lossList\n",
    "        for i in range(0, NumberOfGenerators):\n",
    "            if i != BestPerformingGenerator:\n",
    "                prev = Generators[i]\n",
    "                Generators[i] = Generator()\n",
    "                Generators[i].load_state_dict(Generators[BestPerformingGenerator].state_dict())\n",
    "                GOptimizers[i] = torch.optim.Adam(Generators[i].parameters(), lr = 0.0001)\n",
    "                GOptimizers[i].load_state_dict(GOptimizers[BestPerformingGenerator].state_dict())\n",
    "                #Generators[i] = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "                #GOptimizers[i] = torch.optim.Adam(Generators[i].parameters(), lr = 0.0001)\n",
    "                #copy.deepcopy(GOptimizers[BestPerformingGenerator])\n",
    "                if Generators[i] == prev:\n",
    "                    print 'SAME'\n",
    "\n",
    "        #print epoch\n",
    "        #print BestPerformingGenerator\n",
    "        print 'Epoch [{}/{}], Discriminator {:.4f}, Best Generator[{}] {:.4f}'.format(epoch+1, num_epochs, D_loss.data[0], BestPerformingGenerator, GeneratorLoss[BestPerformingGenerator].data[0])\n",
    "        pic = Generators[BestPerformingGenerator](var(torch.randn(batch_size, Generator_input))) #(fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, imgDim, imgDim) \n",
    "        outputImages.append(pic)\n",
    "        #torchvision.utils.save_image(pic.data, path+'image_{}.png'.format(epoch))   \n",
    "        save_image(pic, path+'image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE COPY: Epoch [1/30], Discriminator 0.8864, Best Generator 1.7188\n",
      "Epoch [1/30], Discriminator 0.8864, Best Generator 1.7188\n",
      "BEFORE COPY: Epoch [2/30], Discriminator 0.9336, Best Generator 1.1309\n",
      "Epoch [2/30], Discriminator 0.9336, Best Generator 1.1309\n",
      "BEFORE COPY: Epoch [3/30], Discriminator 0.6312, Best Generator 1.7462\n",
      "Epoch [3/30], Discriminator 0.6312, Best Generator 1.7462\n",
      "BEFORE COPY: Epoch [4/30], Discriminator 0.6067, Best Generator 1.1341\n",
      "Epoch [4/30], Discriminator 0.6067, Best Generator 1.1341\n",
      "BEFORE COPY: Epoch [5/30], Discriminator 0.0018, Best Generator 8.0786\n",
      "Epoch [5/30], Discriminator 0.0018, Best Generator 8.0786\n",
      "BEFORE COPY: Epoch [6/30], Discriminator 0.0011, Best Generator 8.8595\n",
      "Epoch [6/30], Discriminator 0.0011, Best Generator 8.8595\n",
      "BEFORE COPY: Epoch [7/30], Discriminator 0.0004, Best Generator 9.4714\n",
      "Epoch [7/30], Discriminator 0.0004, Best Generator 9.4714\n",
      "BEFORE COPY: Epoch [8/30], Discriminator 0.0004, Best Generator 10.2284\n",
      "Epoch [8/30], Discriminator 0.0004, Best Generator 10.2284\n",
      "BEFORE COPY: Epoch [9/30], Discriminator 0.0003, Best Generator 10.6489\n",
      "Epoch [9/30], Discriminator 0.0003, Best Generator 10.6489\n",
      "BEFORE COPY: Epoch [10/30], Discriminator 0.0002, Best Generator 11.2527\n",
      "Epoch [10/30], Discriminator 0.0002, Best Generator 11.2527\n",
      "BEFORE COPY: Epoch [11/30], Discriminator 0.0002, Best Generator 11.5787\n",
      "Epoch [11/30], Discriminator 0.0002, Best Generator 11.5787\n",
      "BEFORE COPY: Epoch [12/30], Discriminator 0.0000, Best Generator 12.3199\n",
      "Epoch [12/30], Discriminator 0.0000, Best Generator 12.3199\n",
      "BEFORE COPY: Epoch [13/30], Discriminator 0.0000, Best Generator 12.7369\n",
      "Epoch [13/30], Discriminator 0.0000, Best Generator 12.7369\n",
      "BEFORE COPY: Epoch [14/30], Discriminator 0.0001, Best Generator 12.9572\n",
      "Epoch [14/30], Discriminator 0.0001, Best Generator 12.9572\n",
      "BEFORE COPY: Epoch [15/30], Discriminator 0.0000, Best Generator 13.5776\n",
      "Epoch [15/30], Discriminator 0.0000, Best Generator 13.5776\n",
      "BEFORE COPY: Epoch [16/30], Discriminator 0.0000, Best Generator 13.7484\n",
      "Epoch [16/30], Discriminator 0.0000, Best Generator 13.7484\n",
      "BEFORE COPY: Epoch [17/30], Discriminator 0.0000, Best Generator 14.2752\n",
      "Epoch [17/30], Discriminator 0.0000, Best Generator 14.2752\n",
      "BEFORE COPY: Epoch [18/30], Discriminator 0.0000, Best Generator 14.8879\n",
      "Epoch [18/30], Discriminator 0.0000, Best Generator 14.8879\n",
      "BEFORE COPY: Epoch [19/30], Discriminator 0.0000, Best Generator 15.7351\n",
      "Epoch [19/30], Discriminator 0.0000, Best Generator 15.7351\n",
      "BEFORE COPY: Epoch [20/30], Discriminator 0.0000, Best Generator 16.0015\n",
      "Epoch [20/30], Discriminator 0.0000, Best Generator 16.0015\n",
      "BEFORE COPY: Epoch [21/30], Discriminator 0.0000, Best Generator 16.2272\n",
      "Epoch [21/30], Discriminator 0.0000, Best Generator 16.2272\n",
      "BEFORE COPY: Epoch [22/30], Discriminator 0.0000, Best Generator 17.0610\n",
      "Epoch [22/30], Discriminator 0.0000, Best Generator 17.0610\n",
      "BEFORE COPY: Epoch [23/30], Discriminator 0.0000, Best Generator 17.5944\n",
      "Epoch [23/30], Discriminator 0.0000, Best Generator 17.5944\n",
      "BEFORE COPY: Epoch [24/30], Discriminator 0.0000, Best Generator 18.1572\n",
      "Epoch [24/30], Discriminator 0.0000, Best Generator 18.1572\n",
      "BEFORE COPY: Epoch [25/30], Discriminator 0.0000, Best Generator 18.8665\n",
      "Epoch [25/30], Discriminator 0.0000, Best Generator 18.8665\n",
      "BEFORE COPY: Epoch [26/30], Discriminator 0.0000, Best Generator 19.0696\n",
      "Epoch [26/30], Discriminator 0.0000, Best Generator 19.0696\n",
      "BEFORE COPY: Epoch [27/30], Discriminator 0.0000, Best Generator 19.4422\n",
      "Epoch [27/30], Discriminator 0.0000, Best Generator 19.4422\n",
      "BEFORE COPY: Epoch [28/30], Discriminator 0.0000, Best Generator 19.8113\n",
      "Epoch [28/30], Discriminator 0.0000, Best Generator 19.8113\n",
      "BEFORE COPY: Epoch [29/30], Discriminator 0.0000, Best Generator 20.1573\n",
      "Epoch [29/30], Discriminator 0.0000, Best Generator 20.1573\n",
      "BEFORE COPY: Epoch [30/30], Discriminator 0.0000, Best Generator 20.7542\n",
      "Epoch [30/30], Discriminator 0.0000, Best Generator 20.7542\n"
     ]
    }
   ],
   "source": [
    "#train(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2649.7405613660812, 2830.7473720908165, 2629.8580592870712]\n",
      "Epoch [1/30], Discriminator 0.0339, Best Generator[1] 7.3123\n",
      "[3534.8448543548584, 3537.0058178901672, 3502.87171459198]\n",
      "Epoch [2/30], Discriminator 0.1160, Best Generator[1] 4.9719\n",
      "[3622.894699573517, 3672.117779493332, 3126.534282207489]\n",
      "Epoch [3/30], Discriminator 0.0432, Best Generator[1] 5.5047\n",
      "[3987.6273460388184, 3774.0546247959137, 3823.7598333358765]\n",
      "Epoch [4/30], Discriminator 0.0684, Best Generator[0] 6.6018\n",
      "[4783.176373958588, 4612.59037399292, 4695.462302207947]\n",
      "Epoch [5/30], Discriminator 0.0834, Best Generator[0] 6.0378\n",
      "[4161.950085639954, 4480.347915649414, 4237.211054325104]\n",
      "Epoch [6/30], Discriminator 0.1502, Best Generator[1] 8.0270\n",
      "[4302.498923301697, 4554.430536270142, 4234.160178184509]\n",
      "Epoch [7/30], Discriminator 0.0904, Best Generator[1] 7.4961\n",
      "[4498.108927726746, 4279.703058719635, 4599.574656486511]\n",
      "Epoch [8/30], Discriminator 0.1201, Best Generator[2] 6.5851\n",
      "[4955.929331302643, 4864.478014469147, 5055.658118247986]\n",
      "Epoch [9/30], Discriminator 0.0392, Best Generator[2] 6.8419\n",
      "[5262.761629104614, 5243.282537460327, 4975.955454349518]\n",
      "Epoch [10/30], Discriminator 0.0251, Best Generator[0] 9.6440\n",
      "[5340.821804523468, 5174.559908866882, 5221.227931499481]\n",
      "Epoch [11/30], Discriminator 0.0517, Best Generator[0] 8.1901\n",
      "[5590.7118673324585, 5193.413860797882, 5436.950525760651]\n",
      "Epoch [12/30], Discriminator 0.0330, Best Generator[0] 10.7297\n",
      "[5425.909373283386, 5237.830339431763, 5360.9649176597595]\n",
      "Epoch [13/30], Discriminator 0.0489, Best Generator[0] 10.2003\n",
      "[5688.187469005585, 5494.860065937042, 5494.939154148102]\n",
      "Epoch [14/30], Discriminator 0.1259, Best Generator[0] 9.8434\n",
      "[5458.704341888428, 5474.054999828339, 5576.809480190277]\n",
      "Epoch [15/30], Discriminator 0.0453, Best Generator[2] 7.7525\n",
      "[5647.264901638031, 5439.824848175049, 5454.239777088165]\n",
      "Epoch [16/30], Discriminator 0.0222, Best Generator[0] 9.0476\n"
     ]
    }
   ],
   "source": [
    "# Load model instead of deep copy\n",
    "train(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[856.9920598268509, 803.1024285107851, 851.8648067414761]\n",
      "Epoch [1/40], Discriminator 0.4304, Best Generator[1] 4.6023\n",
      "[1054.6738081872463, 1334.7822082042694, 1052.1758828014135]\n",
      "Epoch [2/40], Discriminator 0.9626, Best Generator[2] 0.2424\n",
      "[1736.5196833498776, 1736.0395818315446, 1815.742018699646]\n",
      "Epoch [3/40], Discriminator 0.3986, Best Generator[1] 0.2782\n",
      "[1382.5161429196596, 1580.1552543640137, 1371.2793620675802]\n",
      "Epoch [4/40], Discriminator 0.9156, Best Generator[2] 0.3780\n",
      "[1281.1298932731152, 1282.6176551878452, 1666.1951867341995]\n",
      "Epoch [5/40], Discriminator 0.3574, Best Generator[0] 0.1930\n",
      "[1786.1965844631195, 870.0297492556274, 869.3980573303998]\n",
      "Epoch [6/40], Discriminator 0.3847, Best Generator[2] 0.1438\n",
      "[843.1533146132715, 844.1812381210038, 1685.6768636703491]\n",
      "Epoch [7/40], Discriminator 0.7598, Best Generator[0] 0.0019\n",
      "[1026.7727580076316, 272.8395392104285, 274.05790696816985]\n",
      "Epoch [8/40], Discriminator 0.4641, Best Generator[1] 0.1701\n",
      "[1738.527152934541, 1527.2031897902489, 1724.3378050304746]\n",
      "Epoch [9/40], Discriminator 0.5665, Best Generator[1] 1.9537\n",
      "[920.9236476421356, 1258.8692388534546, 913.5881178975105]\n",
      "Epoch [10/40], Discriminator 0.4006, Best Generator[2] 0.8905\n",
      "[1136.4622035697103, 1145.7641117274761, 1592.346683382988]\n",
      "Epoch [11/40], Discriminator 0.5943, Best Generator[0] 0.3178\n",
      "[1756.3262034654617, 1271.7948278188705, 1272.1038897708058]\n",
      "Epoch [12/40], Discriminator 0.3991, Best Generator[1] 0.1240\n",
      "[1078.137532569468, 1880.5661512762308, 1079.5790440663695]\n",
      "Epoch [13/40], Discriminator 0.4811, Best Generator[0] 0.1000\n",
      "[1835.7224929779768, 1747.5766119211912, 1749.5129355490208]\n",
      "Epoch [14/40], Discriminator 0.2871, Best Generator[1] 0.1957\n",
      "[1300.0840281248093, 1984.7457265257835, 1287.8278271108866]\n",
      "Epoch [15/40], Discriminator 0.2966, Best Generator[2] 0.2050\n",
      "[1900.1598555305973, 1905.7714022286236, 2122.0290681123734]\n",
      "Epoch [16/40], Discriminator 0.3097, Best Generator[0] 0.0930\n",
      "[2104.9517334401608, 953.032540893415, 950.6426187164616]\n",
      "Epoch [17/40], Discriminator 0.3028, Best Generator[2] 0.0428\n",
      "[971.2384094954468, 974.5227369037457, 2190.4541893601418]\n",
      "Epoch [18/40], Discriminator 0.3790, Best Generator[0] 0.0040\n",
      "[2240.0602054297924, 1881.6838817619719, 1880.0753574676346]\n",
      "Epoch [19/40], Discriminator 0.3677, Best Generator[2] 0.0031\n",
      "[1195.872444877401, 1196.859419381246, 2290.4458743650466]\n",
      "Epoch [20/40], Discriminator 0.1879, Best Generator[0] 0.1309\n",
      "[2459.196710050106, 777.2364097826649, 780.2356910030358]\n",
      "Epoch [21/40], Discriminator 0.3078, Best Generator[1] 0.1586\n",
      "[1559.4249731362215, 2646.826313316822, 1562.2235896728234]\n",
      "Epoch [22/40], Discriminator 0.1649, Best Generator[0] 0.0006\n",
      "[2341.016333884094, 1349.4908470744267, 1346.286815050291]\n",
      "Epoch [23/40], Discriminator 0.2307, Best Generator[2] 0.1007\n",
      "[1883.9395901672542, 1885.8269568514079, 2475.2950426340103]\n",
      "Epoch [24/40], Discriminator 0.1376, Best Generator[0] 0.0681\n",
      "[2731.6187206208706, 1147.1349485386163, 1140.6236384361982]\n",
      "Epoch [25/40], Discriminator 0.2461, Best Generator[2] 0.1127\n",
      "[1757.7430075146258, 1762.2815098781139, 3035.5109964609146]\n",
      "Epoch [26/40], Discriminator 0.2748, Best Generator[0] 0.0215\n",
      "[2676.661723136902, 2221.658841662109, 2218.0906108915806]\n",
      "Epoch [27/40], Discriminator 0.1649, Best Generator[2] 0.0467\n",
      "[1278.6739176474512, 1281.5947484187782, 2688.160478055477]\n",
      "Epoch [28/40], Discriminator 0.2426, Best Generator[0] 0.1304\n",
      "[2792.371824860573, 2123.935339411022, 2123.752914842218]\n",
      "Epoch [29/40], Discriminator 0.3262, Best Generator[2] 0.0068\n",
      "[1411.93895589374, 1411.628830594942, 2611.823527369648]\n",
      "Epoch [30/40], Discriminator 0.3122, Best Generator[1] 0.1149\n",
      "[1831.1382739953697, 2863.792358517647, 1827.003133090213]\n",
      "Epoch [31/40], Discriminator 0.4056, Best Generator[2] 0.0276\n",
      "[1500.5683856757823, 1504.1713867945946, 2862.48747728765]\n",
      "Epoch [32/40], Discriminator 0.2974, Best Generator[0] 0.0014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3058ca475f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# With optimizer on the fly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8a95a2cb66ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(BestPerformingGenerator, num_epochs, d_iter)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlossList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNumberOfGenerators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2389\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m# may change to (mode, 0, 1) post-1.1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m             im = im._new(\n\u001b[1;32m   2393\u001b[0m                 \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0m_close_exclusive_fp_after_loading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;31m# FIXME: take \"new\" parameters / other image?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# FIXME: turn mode and size into delegating properties?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# With optimizer on the fly\n",
    "train(0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[872.1570700109005, 662.0861651301384, 609.2562948316336]\n",
      "Epoch [1/30], Discriminator 0.6847, Best Generator[0] 1.7367\n",
      "[814.5087671279907, 751.060758471489, 748.6468422412872]\n",
      "Epoch [2/30], Discriminator 1.0386, Best Generator[0] 1.1394\n",
      "[1001.8705675601959, 402.21531569585204, 399.4936091527343]\n",
      "Epoch [3/30], Discriminator 0.8658, Best Generator[0] 2.0115\n",
      "[1254.4419853687286, 850.1604254692793, 845.96289460361]\n",
      "Epoch [4/30], Discriminator 0.4126, Best Generator[0] 2.5391\n",
      "[1661.9885839223862, 1183.961763634812, 1223.4222673280165]\n",
      "Epoch [5/30], Discriminator 0.4755, Best Generator[0] 3.0569\n",
      "[1639.9664514064789, 1637.8508403003216, 1646.1216702461243]\n",
      "Epoch [6/30], Discriminator 0.5279, Best Generator[2] 0.4772\n",
      "[1645.3805298805237, 1632.3828236460686, 1544.1907473802567]\n",
      "Epoch [7/30], Discriminator 0.4334, Best Generator[0] 0.8038\n",
      "[1624.6379365324974, 1345.9067988991737, 1343.315298974514]\n",
      "Epoch [8/30], Discriminator 0.5002, Best Generator[0] 2.7455\n",
      "[2061.575703859329, 1457.665353178978, 1395.583261191845]\n",
      "Epoch [9/30], Discriminator 0.5804, Best Generator[0] 2.5811\n",
      "[1755.7334052324295, 1126.5460166931152, 1138.7776359915733]\n",
      "Epoch [10/30], Discriminator 0.4904, Best Generator[0] 3.1247\n",
      "[1841.2697052955627, 1111.8885192871094, 1095.6448769569397]\n",
      "Epoch [11/30], Discriminator 0.3857, Best Generator[0] 4.2212\n",
      "[2037.2302458286285, 1630.1399109959602, 1612.7301331460476]\n",
      "Epoch [12/30], Discriminator 0.3690, Best Generator[0] 3.2038\n",
      "[2134.0492448806763, 1313.1974902749062, 1295.0818182229996]\n",
      "Epoch [13/30], Discriminator 0.2966, Best Generator[0] 3.1558\n",
      "[2251.631275177002, 1256.6901438832283, 1264.8015676736832]\n",
      "Epoch [14/30], Discriminator 0.2301, Best Generator[0] 4.0189\n",
      "[2211.767878293991, 1462.0209045410156, 1473.4623212218285]\n",
      "Epoch [15/30], Discriminator 0.3156, Best Generator[0] 3.8568\n",
      "[2252.7424585819244, 1604.3273143172264, 1639.3052503466606]\n",
      "Epoch [16/30], Discriminator 0.3686, Best Generator[0] 4.0857\n",
      "[2232.465948343277, 1760.5494663119316, 1768.2756642103195]\n",
      "Epoch [17/30], Discriminator 0.4316, Best Generator[0] 3.9720\n",
      "[2446.165271759033, 1822.210275053978, 1884.2799251675606]\n",
      "Epoch [18/30], Discriminator 0.1943, Best Generator[0] 3.9451\n",
      "[2395.9150722026825, 1351.4331141710281, 1326.8580349683762]\n",
      "Epoch [19/30], Discriminator 0.4404, Best Generator[0] 4.1073\n",
      "[2348.1448237895966, 1273.567288517952, 1311.2974657416344]\n",
      "Epoch [20/30], Discriminator 0.2960, Best Generator[0] 3.5321\n",
      "[2409.535304546356, 1782.260391652584, 1728.586496591568]\n",
      "Epoch [21/30], Discriminator 0.2539, Best Generator[0] 4.9073\n",
      "[2449.4630858898163, 1369.4856013059616, 1399.2090330123901]\n",
      "Epoch [22/30], Discriminator 0.1901, Best Generator[0] 4.7282\n",
      "[2473.216210126877, 1619.7988632321358, 1623.273171544075]\n",
      "Epoch [23/30], Discriminator 0.2810, Best Generator[0] 4.3101\n",
      "[2560.063740491867, 1665.7799058556557, 1723.9129244089127]\n",
      "Epoch [24/30], Discriminator 0.1581, Best Generator[0] 4.2523\n",
      "[2513.8959436416626, 1548.1140825748444, 1536.6563726067543]\n",
      "Epoch [25/30], Discriminator 0.4184, Best Generator[0] 3.7386\n",
      "[2554.2282292842865, 1642.1847410798073, 1683.7064735293388]\n",
      "Epoch [26/30], Discriminator 0.3158, Best Generator[0] 4.5012\n",
      "[2538.237756729126, 1732.5801632404327, 1736.3425637483597]\n",
      "Epoch [27/30], Discriminator 0.1435, Best Generator[0] 4.5066\n",
      "[2551.242653131485, 1674.7433705329895, 1642.2202155590057]\n",
      "Epoch [28/30], Discriminator 0.3953, Best Generator[0] 4.4175\n",
      "[2608.9233951568604, 1636.0791056752205, 1719.6294510364532]\n",
      "Epoch [29/30], Discriminator 0.2822, Best Generator[0] 4.3083\n",
      "[2585.7635400295258, 1774.507214486599, 1787.6149329543114]\n",
      "Epoch [30/30], Discriminator 0.3816, Best Generator[0] 4.3661\n"
     ]
    }
   ],
   "source": [
    "# With optimizer on the fly and max loss\n",
    "train(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2778.058117568493, 2917.6230896115303, 2697.726538479328]\n",
      "Epoch [1/30], Discriminator 0.0416, Best Generator[1] 5.6720\n",
      "[3695.9072647094727, 3356.031274318695, 3374.9563450813293]\n",
      "Epoch [2/30], Discriminator 0.1799, Best Generator[0] 6.3682\n",
      "[3256.957720041275, 3510.96928858757, 3557.807953119278]\n",
      "Epoch [3/30], Discriminator 0.0258, Best Generator[2] 6.8425\n",
      "[4142.80516242981, 4470.754581928253, 3614.0237057209015]\n",
      "Epoch [4/30], Discriminator 0.0879, Best Generator[1] 6.4516\n",
      "[4529.959128856659, 3948.716283798218, 4235.133533000946]\n",
      "Epoch [5/30], Discriminator 0.0387, Best Generator[0] 8.0247\n",
      "[4343.090248584747, 4722.502594470978, 4257.555803775787]\n",
      "Epoch [6/30], Discriminator 0.2769, Best Generator[1] 5.8655\n",
      "[4618.889126300812, 4463.452397823334, 4359.163161277771]\n",
      "Epoch [7/30], Discriminator 0.2528, Best Generator[0] 6.2346\n",
      "[4684.915420532227, 4336.271741390228, 4291.608334541321]\n",
      "Epoch [8/30], Discriminator 0.1100, Best Generator[0] 7.7472\n",
      "[4734.094176769257, 4796.5427713394165, 4795.7561893463135]\n",
      "Epoch [9/30], Discriminator 0.1253, Best Generator[1] 6.9403\n",
      "[5049.959019184113, 5027.6559336185455, 5120.212819099426]\n",
      "Epoch [10/30], Discriminator 0.0754, Best Generator[2] 6.8321\n",
      "[5174.600156784058, 5256.379452705383, 5157.375615596771]\n",
      "Epoch [11/30], Discriminator 0.1244, Best Generator[1] 7.6583\n",
      "[5001.470520496368, 5049.887799739838, 4872.8134207725525]\n",
      "Epoch [12/30], Discriminator 0.0142, Best Generator[1] 7.1265\n",
      "[5400.529816150665, 5309.533566951752, 5343.8241357803345]\n",
      "Epoch [13/30], Discriminator 0.0229, Best Generator[0] 8.3038\n",
      "[5223.159967422485, 5364.416179656982, 5361.684566497803]\n",
      "Epoch [14/30], Discriminator 0.0364, Best Generator[1] 8.7717\n",
      "[5417.0434284210205, 5463.120951652527, 4973.908950805664]\n",
      "Epoch [15/30], Discriminator 0.0309, Best Generator[1] 8.7464\n",
      "[5653.333395957947, 5171.138589859009, 5531.204066753387]\n",
      "Epoch [16/30], Discriminator 0.0559, Best Generator[0] 8.1740\n",
      "[5531.024948596954, 5656.0243310928345, 5634.804122924805]\n",
      "Epoch [17/30], Discriminator 0.0575, Best Generator[1] 7.7896\n",
      "[5680.24044418335, 5400.6087074279785, 5439.811349391937]\n",
      "Epoch [18/30], Discriminator 0.0341, Best Generator[0] 7.5349\n",
      "[5360.651843070984, 5336.985419750214, 5450.201311588287]\n",
      "Epoch [19/30], Discriminator 0.0186, Best Generator[2] 7.9655\n",
      "[5578.952021598816, 5580.399248123169, 5202.668723583221]\n",
      "Epoch [20/30], Discriminator 0.0143, Best Generator[1] 8.4579\n",
      "[5301.0527811050415, 5475.551202774048, 5285.052348613739]\n",
      "Epoch [21/30], Discriminator 0.0782, Best Generator[1] 8.3499\n",
      "[6101.800065040588, 5427.678186416626, 5899.076765537262]\n",
      "Epoch [22/30], Discriminator 0.0909, Best Generator[0] 10.0620\n",
      "[5653.270559310913, 5647.117569923401, 5603.526169300079]\n",
      "Epoch [23/30], Discriminator 0.0300, Best Generator[0] 10.4779\n",
      "[5648.005443096161, 5485.590974807739, 5443.540237903595]\n",
      "Epoch [24/30], Discriminator 0.0662, Best Generator[0] 10.5627\n",
      "[5732.1653509140015, 5481.707170963287, 5396.85217666626]\n",
      "Epoch [25/30], Discriminator 0.0424, Best Generator[0] 11.1002\n",
      "[5923.800654411316, 6075.984002113342, 6023.765144824982]\n",
      "Epoch [26/30], Discriminator 0.0601, Best Generator[1] 8.8528\n",
      "[6104.5225286483765, 5588.120784282684, 6018.230801582336]\n",
      "Epoch [27/30], Discriminator 0.0528, Best Generator[0] 6.8982\n",
      "[5405.457807064056, 5598.817863941193, 5503.100583076477]\n",
      "Epoch [28/30], Discriminator 0.0105, Best Generator[1] 9.6997\n",
      "[5740.616246700287, 5446.834491729736, 5789.677504062653]\n",
      "Epoch [29/30], Discriminator 0.0117, Best Generator[2] 13.0937\n",
      "[5986.13765668869, 5840.38082075119, 5535.985820770264]\n",
      "Epoch [30/30], Discriminator 0.0173, Best Generator[0] 11.2642\n"
     ]
    }
   ],
   "source": [
    "train(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(G.state_dict(), './Generator.pkl')\n",
    "#torch.save(D.state_dict(), './Discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator.load_state_dict(torch.load('Generator200.pkl'))\n",
    "#Discriminator.load_state_dict(torch.load('Discriminator200.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imageio\n",
    "#imageio.mimsave(path + 'MNIST_MaxNew_{:d}'.format(30) + '.gif', outputImages, fps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
