{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as tutils\n",
    "import imageio\n",
    "import pickle\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options being used \n",
    "batch_size = 100\n",
    "imgDim = 28\n",
    "path = './genImg/'\n",
    "showPlot = False\n",
    "savePlot = True\n",
    "num_epochs = 200\n",
    "IS_CUDA = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), \n",
    "                                     std=(0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(root='../data',\n",
    "                         train=True,\n",
    "                         transform=transform,\n",
    "                         download=True)\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper routines\n",
    "if torch.cuda.is_available():\n",
    "    IS_CUDA = True\n",
    "    \n",
    "def var(x):\n",
    "    if IS_CUDA:\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def generate_animation(root, epoch, name):\n",
    "    images = []\n",
    "    for e in range(epoch):\n",
    "        img_name = root+'/image_'+str(e)+'.png'\n",
    "        images.append(imageio.imread(img_name))\n",
    "    imageio.mimsave(root+ '/' + name +'.gif', images, fps=5)\n",
    "\n",
    "def drawLossPlot(generatorLoss, discriminatorLoss, showPlot = False, savePlot = True, loc = \"./\"):\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Vanilla GAN Loss')\n",
    "    plt.plot(generatorLoss, label='Generator Loss')\n",
    "    plt.plot(discriminatorLoss, label='Discriminator Loss')\n",
    "    legend = plt.legend(loc='upper right', shadow=True)\n",
    "    \n",
    "    if showPlot:\n",
    "        plt.show()\n",
    "    if savePlot:\n",
    "        plt.savefig(loc+'Loss_Plot_Vanilla_GAN_'+str(num_epochs)+'.png')\n",
    "\n",
    "def save_image(pic, path):\n",
    "    grid = torchvision.utils.make_grid(pic, nrow=8, padding=2)\n",
    "    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    im.save(path)\n",
    "\n",
    "class LossModule: \n",
    "    def __init__(self, numberOfGens = 1):\n",
    "        self.D_loss = []\n",
    "        self.G_loss = []\n",
    "        self.Many_G_loss = [[]] * (numberOfGens+1)\n",
    "\n",
    "    def insertDiscriminatorLoss(self, lossVal):\n",
    "        self.D_loss.append(lossVal)\n",
    "    \n",
    "    def insertGeneratorLoss(self, lossVal):\n",
    "        self.G_loss.append(lossVal)\n",
    "    \n",
    "    def insertGeneratorList(self, lossList):\n",
    "        for i in range(0, len(lossList)):\n",
    "            self.Many_G_loss[i].append(lossList[i])\n",
    "        \n",
    "    def getDiscriminatorLoss(self):\n",
    "        return self.D_loss\n",
    "    \n",
    "    def getGeneratorLoss(self):\n",
    "        return self.G_loss\n",
    "    \n",
    "    def getGeneratorsList(self):\n",
    "        return self.Many_G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "Generator_input = 64\n",
    "Generator = nn.Sequential(\n",
    "        nn.Linear(Generator_input, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 784),\n",
    "        nn.Tanh())\n",
    "\n",
    "Discriminator = nn.Sequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256,1),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "#Gen = Generator()\n",
    "Generators = []\n",
    "GOptimizers = []\n",
    "NumberOfGenerators = 3\n",
    "for i in range(NumberOfGenerators):\n",
    "    Generators.append(copy.deepcopy(Generator))\n",
    "    #Generators.append(Generator()\n",
    "\n",
    "if IS_CUDA:\n",
    "    D.cuda()\n",
    "    for each in Generators:\n",
    "        each.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossManager = LossModule(numberOfGens = NumberOfGenerators)\n",
    "lossCriterion = nn.BCELoss()\n",
    "D_opt = torch.optim.Adam(Discriminator.parameters(), lr = 0.0001)\n",
    "#G_opt = torch.optim.Adam(Gen.parameters(), lr = 0.0001)\n",
    "GOptimizers = []\n",
    "for each in Generators:\n",
    "    GOptimizers.append(torch.optim.Adam(each.parameters(), lr = 0.0001))\n",
    "\n",
    "fixed_x = var(torch.randn(batch_size, Generator_input))\n",
    "\n",
    "GeneratorLoss = []\n",
    "def backPropGenerator(index, GeneratorLoss):\n",
    "    Generators[index].zero_grad()\n",
    "    GeneratorLoss[index].backward()\n",
    "    GOptimizers[index].step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model instead of deepcopy\n",
    "\n",
    "outputImages = []\n",
    "def train(BestPerformingGenerator, num_epochs = 10, d_iter = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        lossList = [0.0] * NumberOfGenerators\n",
    "        for data in data_loader:\n",
    "            image, _  = data\n",
    "            image = var(image.view(image.size(0),  -1))\n",
    "            \n",
    "            # Train Discriminator\n",
    "            #for k in range(0, d_iter):\n",
    "            for each in Generators:\n",
    "                D_real = Discriminator(image)\n",
    "                # For Log(1 - D(G(Z)))\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                #print Z_noise.shape\n",
    "                #print type(Gen)\n",
    "                G_fake = each(Z_noise) #Generators[BestPerformingGenerator](Z_noise)\n",
    "                #print G_fake.shape\n",
    "                D_fake = Discriminator(G_fake)\n",
    "\n",
    "                # Calculate Discriminator Loss\n",
    "                D_real_loss = lossCriterion(D_real, var(torch.ones(batch_size, 1)))\n",
    "                D_fake_loss = lossCriterion(D_fake, var(torch.zeros(batch_size, 1)))\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "                # Backprop Discriminator\n",
    "                Discriminator.zero_grad()\n",
    "                D_loss.backward()\n",
    "                D_opt.step()\n",
    "                #print 'Discriminator Loop for: {}: {}'.format(i, D_loss.data[0])\n",
    "   \n",
    "            # Find best performing Generator\n",
    "            i = 0\n",
    "            GeneratorLoss = []\n",
    "            for each, each_opt in zip(Generators, GOptimizers):\n",
    "                Z_noise = var(torch.randn(batch_size, Generator_input))\n",
    "                G_fake = each(Z_noise)\n",
    "                #print G_fake1.shape\n",
    "                #print type(each)\n",
    "                D_fake = Discriminator(G_fake)\n",
    "                # Compute Generator Loss\n",
    "                G_loss = lossCriterion(D_fake, var(torch.ones(batch_size, 1)))\n",
    "                GeneratorLoss.append(G_loss)\n",
    "                lossList[i] += (float(G_loss.data[0]))\n",
    "                i = i + 1\n",
    "                Discriminator.zero_grad()\n",
    "                each.zero_grad()\n",
    "                G_loss.backward()\n",
    "                each_opt.step()\n",
    "                #backPropGenerator(i, GeneratorLoss)\n",
    "                #print 'Generator Loop for: {}: {}'.format(i, G_loss.data[0])\n",
    "            \n",
    "            #print lossList\n",
    "            #print type(lossList[0])\n",
    "        BestPerformingGenerator = lossList.index(max(lossList)) # earlier was min\n",
    "        print lossList\n",
    "        for i in range(0, NumberOfGenerators):\n",
    "            if i != BestPerformingGenerator:\n",
    "                prev = Generators[i]\n",
    "                Generators[i] = copy.deepcopy(Generator)\n",
    "                Generators[i].load_state_dict(Generators[BestPerformingGenerator].state_dict())\n",
    "                GOptimizers[i] = torch.optim.Adam(Generators[i].parameters(), lr = 0.0001)\n",
    "                GOptimizers[i].load_state_dict(GOptimizers[BestPerformingGenerator].state_dict())\n",
    "                #Generators[i] = copy.deepcopy(Generators[BestPerformingGenerator])\n",
    "                #GOptimizers[i] = torch.optim.Adam(Generators[i].parameters(), lr = 0.0001)\n",
    "                #copy.deepcopy(GOptimizers[BestPerformingGenerator])\n",
    "                if Generators[i] == prev:\n",
    "                    print 'SAME'\n",
    "\n",
    "        #print epoch\n",
    "        print BestPerformingGenerator\n",
    "        print 'Epoch [{}/{}], Discriminator {:.4f}, Best Generator[{}] {:.4f}'.format(epoch+1, num_epochs, D_loss.data[0], BestPerformingGenerator, GeneratorLoss[BestPerformingGenerator].data[0])\n",
    "        lossManager.insertDiscriminatorLoss(D_loss.data[0])\n",
    "        lossManager.insertGeneratorLoss(G_loss.data[0])\n",
    "        lossManager.insertGeneratorList(lossList)\n",
    "        pic = Generators[BestPerformingGenerator](fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, 28, 28) \n",
    "        pic = denorm(pic.data)\n",
    "        outputImages.append(pic)\n",
    "        #torchvision.utils.save_image(pic, path+'image_{}.png'.format(epoch))\n",
    "        save_image(pic, path+'image_{}.png'.format(epoch))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2820.4476397037506, 2885.6862288713455, 2652.365994632244]\n",
      "1\n",
      "Epoch [1/5], Discriminator 0.0024, Best Generator[1] 6.4573\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "[4232.179490804672, 4240.152737379074, 4204.9286522865295]\n",
      "1\n",
      "Epoch [2/5], Discriminator 0.0560, Best Generator[1] 3.1899\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "train(0, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns1Q4UMzMLBX/Hy/wbtt+DoXvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f958122de50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Loss for Generator and Discriminator\n",
    "#drawLossPlot(lossManager.getGeneratorLoss(), lossManager.getDiscriminatorLoss(), showPlot = True, savePlot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'Many_G_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-8479f3bad775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlossL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetGeneratorsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-56ce1bcd0a10>\u001b[0m in \u001b[0;36mgetGeneratorsList\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetGeneratorsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMany_G_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'Many_G_loss' is not defined"
     ]
    }
   ],
   "source": [
    "#lossL = lossManager.getGeneratorsList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GIF\n",
    "generate_animation(path, 5, 'Vanilla_Gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(Generator.state_dict(), './Generator.pkl')\n",
    "torch.save(Discriminator.state_dict(), './Discriminator.pkl')\n",
    "pickle.dump(lossManager, open( \"LossManager.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Loss Manager for viewing data of 200 iterations\n",
    "#lossManagerTrained = pickle.load(open( \"200Iteration/LossManager.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawLossPlot(lossManagerTrained.getGeneratorLoss(), lossManagerTrained.getDiscriminatorLoss(), showPlot = False, savePlot = True, loc = \"200Iteration\")\n",
    "#drawLossPlot(lossManagerTrained.getGeneratorLoss(), lossManagerTrained.getDiscriminatorLoss(), showPlot = True, savePlot = False, loc = \"200Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for debugging and testing\n",
    "#Generator.load_state_dict(torch.load('Generator200.pkl'))\n",
    "#Discriminator.load_state_dict(torch.load('Discriminator200.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
