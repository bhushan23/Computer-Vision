{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Functional\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "IsCuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root = './data', train = True,\n",
    "                                       download = True, transform = transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./genImg'):\n",
    "    os.mkdir('./genImg')\n",
    "\n",
    "\n",
    "def imShow(img):\n",
    "    # Denormalize\n",
    "    img = img / 2 + 0.5\n",
    "    npImg = img.numpy()\n",
    "    plt.imshow(np.transpose(npImg, (1, 2, 0)))\n",
    "    \n",
    "    \n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiAowg8ERfiBoAg/EBThB4Ii/EBQ/wHvGZgF1a6mlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64f6518b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleImg = iter(dataset)\n",
    "images, _ = sampleImg.next()\n",
    "imShow(torchvision.utils.make_grid(images))\n",
    "# plt.imshow(to_img(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=128, out_features=64)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Linear(in_features=64, out_features=12)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=12, out_features=3)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=12, out_features=64)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Linear(in_features=64, out_features=128)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=128, out_features=784)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 3)        \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 784),\n",
    "            # nn.ReLU(True)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = AutoEncoder().cuda if IsCuda else AutoEncoder()\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 784])\n",
      "Epoch [1/10], Loss:0.2078\n",
      "torch.Size([96, 784])\n",
      "Epoch [2/10], Loss:0.1766\n",
      "torch.Size([96, 784])\n",
      "Epoch [3/10], Loss:0.1736\n",
      "torch.Size([96, 784])\n",
      "Epoch [4/10], Loss:0.1669\n",
      "torch.Size([96, 784])\n",
      "Epoch [5/10], Loss:0.1497\n",
      "torch.Size([96, 784])\n",
      "Epoch [6/10], Loss:0.1413\n",
      "torch.Size([96, 784])\n",
      "Epoch [7/10], Loss:0.1523\n",
      "torch.Size([96, 784])\n",
      "Epoch [8/10], Loss:0.1458\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in data_loader:\n",
    "        img, _ = data\n",
    "        # print img.shape\n",
    "        img = img.view(img.size(0), -1)\n",
    "        # print img.shape\n",
    "        img = Variable(img).cuda() if IsCuda else Variable(img)\n",
    "        \n",
    "        # Forward\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Log\n",
    "    # if epoch % 10 == 9:\n",
    "    # print output.shape\n",
    "    print 'Epoch [{}/{}], Loss:{:.4f}'.format(epoch+1, num_epochs, loss.data[0])\n",
    "    pic = to_img(output.cpu().data)\n",
    "    save_image(pic, './genImg/image_{}.png'.format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
